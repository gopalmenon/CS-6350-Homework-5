\section{Experiments}
\label{sec:q3}

In this question, you will implement the support vector machine (SVM)
and a variant of random forest which combine SVMs and decision trees.

We will use two datasets for this question:
\begin{enumerate}
\item {\tt semelion handwritten digits data}: This dataset contains
  1593 handwritten digits from around 80 persons were scanned,
  stretched in a rectangular box 16x16 in a gray scale of 256 values.
  Our goal is implement svm in this data set to determine whether is a
  number 6.
\item {\tt madelon}: This is one of five datasets used in the NIPS
  2003 feature selection challenge. There are 2000 examples in
  training set and 600 examples in test set. 
\end{enumerate}

You may reuse your code in decision tree. If \textbf{you have problems
  in decision tree}, please contact with TA to get help. You may use
Java, Python, Matlab, C/C++ for this assignment. If you want to use a
different language, you must contact the instructor first. Any other
language you may want to use \textbf{MUST} run on the CADE machines.

\subsection{Support Vector Machines}
\begin{enumerate}
\item ~[6 points] Implement SVM in handwriting dataset with hyperparameter $C=1$ and $\gamma_0 = 0.01$. Report the accuracy in test set and training set. 

\textbf{Note:}
\begin{enumerate}
\item
 update learning rate according to:
$$\gamma_t = \frac{\gamma_0}{1 +\gamma_0 *t /c}$$
in this question, as well as the following questions related to SVM.
\item
Don't forget to add bias  item as the first dimension of \textbf{x}.
\end{enumerate}

The accuracy ($\frac{TP+TN}{Number of Samples}$) obtained was

    \begin{table}[H]
    \centering
    \begin{tabular}{| c | c |}
      \hline
      Data set & Accuracy  \\
      \hline
      Test & $0.7184$\\
      \hline
      Training & $0.7240$\\
      \hline
    \end{tabular}
    \caption{Handwriting data set accuracy on test and training sets}
  \end{table}    

\item ~[8 points] Run your SVM code on the {\tt madelon} dataset and
  use 5-fold cross-validation to choose suitable parameters. At least
  attempt 6 different values for $C$ and 3 different values for
  $\gamma_0$. Report the average accuracy for each group of parameters.
  Report the accuracy in your test set as well as training set.

  Hint: You should try out $C$ in exponential steps, for example,
  $2^1, 2^{-1}, 2^{-2}, \cdots$.

\begin{longtable}{| p{.30\textwidth}  |  p{.20\textwidth} |p{.20\textwidth}  |} 
      \hline
      Starting Learning Rate $\gamma_0$& Tradeoff Value $C$ & Average Accuracy  \\
      \hline
      $10.0$ & $2.0$ & $0.4940$ \\
      \hline
      $10.0$ & $1.0$ & $0.5885$ \\
      \hline
      $10.0$ & $0.5$ & $0.5000$ \\
      \hline
      $10.0$ & $0.25$ & $0.4880$ \\
      \hline
      $10.0$ & $0.125$ & $0.5000$ \\
      \hline
      $10.0$ & $0.0625$ & $0.5000$ \\
      \hline
      $10.0$ & $0.03125$ & $0.5040$ \\
      \hline
      $10.0$ & $0.015625$ & $0.4870$ \\
      \hline
      $10.0$ & $0.0078125$ & $0.5000$ \\
      \hline
      $10.0$ & $0.00390625$ & $0.5000$ \\
      \hline
      $10.0$ & $0.001953125$ & $0.4980$ \\
      \hline
      $10.0$ & $9.765625E-4$ & $0.5000$ \\
      \hline
      $1.0$ & $2.0$ & $0.5035$ \\
      \hline
      $1.0$ & $1.0$ & $0.5655$ \\
      \hline
      $1.0$ & $0.5$ & $0.4900$ \\
      \hline
      $1.0$ & $0.25$ & $0.5020$ \\
      \hline
      $1.0$ & $0.125$ & $0.5000$ \\
      \hline
      $1.0$ & $0.0625$ & $0.5000$ \\
      \hline
      $1.0$ & $0.03125$ & $0.5000$ \\
      \hline
      $1.0$ & $0.015625$ & $0.4980$ \\
      \hline
      $1.0$ & $0.0078125$ & $0.5000$ \\
      \hline
      $1.0$ & $0.00390625$ & $0.5050$ \\
      \hline
      $1.0$ & $0.001953125$ & $0.5000$ \\
      \hline
      $1.0$ & $9.765625E-4$ & $0.5000$ \\
      \hline
      
      $0.1$ & $2.0$ & $0.5785$ \\
      \hline
      $0.1$ & $1.0$ & $0.5130$ \\
      \hline
      $0.1$ & $0.5$ & $0.5500$ \\
      \hline
      $0.1$ & $0.25$ & $0.4495$ \\
      \hline
      $0.1$ & $0.125$ & $0.5610$ \\
      \hline
      $0.1$ & $0.0625$ & $0.5010$ \\
      \hline
      $0.1$ & $0.03125$ & $0.5030$ \\
      \hline
      $0.1$ & $0.015625$ & $0.5000$ \\
      \hline
      $0.1$ & $0.0078125$ & $0.5000$ \\
      \hline
      $0.1$ & $0.00390625$ & $0.4810$ \\
      \hline
      $0.1$ & $0.001953125$ & $0.5010$ \\
      \hline
      $0.1$ & $9.765625E-4$ & $0.5050$ \\
      \hline
      
      $0.01$ & $2.0$ & $0.5285$ \\
      \hline
      $0.01$ & $1.0$ & $0.5950$ \\
      \hline
      $0.01$ & $0.5$ & $0.5105$ \\
      \hline
      $0.01$ & $0.25$ & $0.4950$ \\
      \hline
      $0.01$ & $0.125$ & $0.5695$ \\
      \hline
      $0.01$ & $0.0625$ & $0.5315$ \\
      \hline
      $0.01$ & $0.03125$ & $0.5245$ \\
      \hline
      $0.01$ & $0.015625$ & $0.5575$ \\
      \hline
      $0.01$ & $0.0078125$ & $0.5565$ \\
      \hline
      $0.01$ & $0.00390625$ & $0.5000$ \\
      \hline
      $0.01$ & $0.001953125$ & $0.5000$ \\
      \hline
      $0.01$ & $9.765625E-4$ & $0.5000$ \\
      \hline
       
      $0.001$ & $2.0$ & $0.5710$ \\
      \hline
      $0.001$ & $1.0$ & $0.5630$ \\
      \hline
      $0.001$ & $0.5$ & $0.5970$ \\
      \hline
      $0.001$ & $0.25$ & $0.5775$ \\
      \hline
      $0.001$ & $0.125$ & $0.5770$ \\
      \hline
      $0.001$ & $0.0625$ & $0.5095$ \\
      \hline
      $0.001$ & $0.03125$ & $0.4615$ \\
      \hline
      $0.001$ & $0.015625$ & $0.4775$ \\
      \hline
      $0.001$ & $0.0078125$ & $0.5545$ \\
      \hline
      $0.001$ & $0.00390625$ & $0.5310$ \\
      \hline
      $0.001$ & $0.001953125$ & $0.5000$ \\
      \hline
      $0.001$ & $9.765625E-4$ & $0.5000$ \\
      \hline
       
      $0.0001$ & $2.0$ & $0.5615$ \\
      \hline
      $0.0001$ & $1.0$ & $0.5630$ \\
      \hline
      $0.0001$ & $0.5$ & $0.5750$ \\
      \hline
      $0.0001$ & $0.25$ & $0.5770$ \\
      \hline
      $0.0001$ & $0.125$ & $0.5890$ \\
      \hline
      $0.0001$ & $0.0625$ & $0.4650$ \\
      \hline
      $0.0001$ & $0.03125$ & $0.5640$ \\
      \hline
      $0.0001$ & $0.015625$ & $0.5620$ \\
      \hline
      $0.0001$ & $0.0078125$ & $0.4875$ \\
      \hline
      $0.0001$ & $0.00390625$ & $0.4940$ \\
      \hline
      $0.0001$ & $0.001953125$ & $0.5000$ \\
      \hline
      $0.0001$ & $9.765625E-4$ & $0.4820$ \\
      \hline
       
      $0.00001$ & $2.0$ & $0.5525$ \\
      \hline
      $0.00001$ & $1.0$ & $0.5880$ \\
      \hline
      $0.00001$ & $0.5$ & $0.5820$ \\
      \hline
      $0.00001$ & $0.25$ & $0.5955$ \\
      \hline
      $0.00001$ & $0.125$ & $0.5965$ \\
      \hline
      $0.00001$ & $0.0625$ & $0.5900$ \\
      \hline
      $0.00001$ & $0.03125$ & $0.4960$ \\
      \hline
      $0.00001$ & $0.015625$ & $0.5180$ \\
      \hline
      $0.00001$ & $0.0078125$ & $0.4995$ \\
      \hline
      $0.00001$ & $0.00390625$ & $0.5000$ \\
      \hline
      $0.00001$ & $0.001953125$ & $0.5000$ \\
      \hline
      $0.00001$ & $9.765625E-4$ & $0.5000$ \\
      \hline
      
      $0.000001$ & $2.0$ & $0.5670$ \\
      \hline
      $0.000001$ & $1.0$ & $0.5880$ \\
      \hline
      $0.000001$ & $0.5$ & $0.6050$ \\
      \hline
      $0.000001$ & $0.25$ & $0.5945$ \\
      \hline
      $0.000001$ & $0.125$ & $0.5690$ \\
      \hline
      $0.000001$ & $0.0625$ & $0.4830$ \\
      \hline
      $0.000001$ & $0.03125$ & $0.4860$ \\
      \hline
      $0.000001$ & $0.015625$ & $0.4860$ \\
      \hline
      $0.000001$ & $0.0078125$ & $0.5000$ \\
      \hline
      $0.000001$ & $0.00390625$ & $0.5000$ \\
      \hline
      $0.000001$ & $0.001953125$ & $0.4860$ \\
      \hline
      $0.000001$ & $9.765625E-4$ & $0.5000$ \\
      \hline
       
      $0.0000001$ & $2.0$ & $0.5860$ \\
      \hline
      $0.0000001$ & $1.0$ & $0.5480$ \\
      \hline
      $0.0000001$ & $0.5$ & $0.5980$ \\
      \hline
      $0.0000001$ & $0.25$ & $0.5850$ \\
      \hline
      $0.0000001$ & $0.125$ & $0.4745$ \\
      \hline
      $0.0000001$ & $0.0625$ & $0.4760$ \\
      \hline
      $0.0000001$ & $0.03125$ & $0.4895$ \\
      \hline
      $0.0000001$ & $0.015625$ & $0.4870$ \\
      \hline
      $0.0000001$ & $0.0078125$ & $0.4820$ \\
      \hline
      $0.0000001$ & $0.00390625$ & $0.5000$ \\
      \hline
      $0.0000001$ & $0.001953125$ & $0.4990$ \\
      \hline
      $0.0000001$ & $9.765625E-4$ & $0.4900$ \\
      \hline
      
      $0.00000001$ & $2.0$ & $0.5420$ \\
      \hline
      $0.00000001$ & $1.0$ & $0.5925$ \\
      \hline
      $0.00000001$ & $0.5$ & $0.5465$ \\
      \hline
      $0.00000001$ & $0.25$ & $0.4955$ \\
      \hline
      $0.00000001$ & $0.125$ & $0.4810$ \\
      \hline
      $0.00000001$ & $0.0625$ & $0.4710$ \\
      \hline
      $0.00000001$ & $0.03125$ & $0.4810$ \\
      \hline
      $0.00000001$ & $0.015625$ & $0.4870$ \\
      \hline
      $0.00000001$ & $0.0078125$ & $0.4810$ \\
      \hline
      $0.00000001$ & $0.00390625$ & $0.4910$ \\
      \hline
      $0.00000001$ & $0.001953125$ & $0.5000$ \\
      \hline
      $0.00000001$ & $9.765625E-4$ & $0.4930$ \\
      \hline    
      
      $0.000000001$ & $2.0$ & $0.5210$ \\
      \hline
      $0.000000001$ & $1.0$ & $0.4920$ \\
      \hline
      $0.000000001$ & $0.5$ & $0.5010$ \\
      \hline
      $0.000000001$ & $0.25$ & $0.4880$ \\
      \hline
      $0.000000001$ & $0.125$ & $0.4850$ \\
      \hline
      $0.000000001$ & $0.0625$ & $0.4780$ \\
      \hline
      $0.000000001$ & $0.03125$ & $0.4740$ \\
      \hline
      $0.000000001$ & $0.015625$ & $0.4740$ \\
      \hline
      $0.000000001$ & $0.0078125$ & $0.4810$ \\
      \hline
      $0.000000001$ & $0.00390625$ & $0.4920$ \\
      \hline
      $0.000000001$ & $0.001953125$ & $0.4750$ \\
      \hline
      $0.000000001$ & $9.765625E-4$ & $0.4910$ \\
      \hline    
      
      
      $0.0000000001$ & $2.0$ & $0.5130$ \\
      \hline
      $0.0000000001$ & $1.0$ & $0.4930$ \\
      \hline
      $0.0000000001$ & $0.5$ & $0.4790$ \\
      \hline
      $0.0000000001$ & $0.25$ & $0.4770$ \\
      \hline
      $0.0000000001$ & $0.125$ & $0.4780$ \\
      \hline
      $0.0000000001$ & $0.0625$ & $0.4710$ \\
      \hline
      $0.0000000001$ & $0.03125$ & $0.4780$ \\
      \hline
      $0.0000000001$ & $0.015625$ & $0.4790$ \\
      \hline
      $0.0000000001$ & $0.0078125$ & $0.5065$ \\
      \hline
      $0.0000000001$ & $0.00390625$ & $0.4750$ \\
      \hline
      $0.0000000001$ & $0.001953125$ & $0.4850$ \\
      \hline
      $0.0000000001$ & $9.765625E-4$ & $0.4870$ \\
      \hline    
     \caption{Madelon data set average accuracy for hyper parameters}
  \end{longtable}  

Due to the extensive cross validation used, the run took around 7 to 8 minutes. The above table was obtained for the SVM run log, that is written into a text file.
    \begin{table}[H]
    \centering
    \begin{tabular}{| c | c |}
      \hline
      Data set & Accuracy  \\
      \hline
      Test & $0.5867$\\
      \hline
      Training & $0.6325$\\
      \hline
    \end{tabular}
    \caption{Madelon data set accuracy on test and training sets}
  \end{table}   

\item ~[6 points] Precision , recall and $ F_1$ score are another
  metrics besides accuracy, which are useful if the dataset is
  unbalanced with respect to the positive and negative examples. To
  compute these quantities, you should count the number of true
  positives (that is, examples that your classifier predicts as
  positive and are truly positive), the false positives (i.e, examples
  that your classifier predicts as positive, but are actually labeled
  negative) and the false negatives (i.e., examples that are predicted
  as negative by your classifier, but are actually positive).
  
  Denote true positives, false positive and false negative as $TP$, $FP$
  and $FN$ respectively. The precision ($p$), recall ($r$) and f-value
  $F_1$ are defined as:
  \begin{eqnarray*}
    p   & = & \frac{TP}{TP + FP} \\
    r   & = & \frac{TP}{TP+FN}   \\
    F_1 & = & 2 \frac{p \cdot r}{p + r} 
  \end{eqnarray*}

  Give precision, recall and $F_1$ score for your classifiers
  constructed in the previous two questions.

    \begin{table}[H]
    \centering
    \begin{tabular}{| c | c | c | c |}
      \hline
      Data set & Precision & Recall & $F_1$ Score  \\
      \hline
      Handwriting test& $0.6476$& $0.9967$& $0.7851$\\
      \hline
      Handwriting training& $0.6650$& $1.0000$& $0.7988$\\
      \hline
      Madelon test& $0.5802$& $0.6267$& $0.6026$\\
      \hline
      Madelon training& $0.6233$& $0.6700$& $0.6458$\\
      \hline
    \end{tabular}
    \caption{Precision, Recall and $F_1$ score for classifiers run on Handwriting and Madelon data sets}
  \end{table}   
\end{enumerate}

\subsection{Ensemble of decision trees}

Recall that a random forest is an ensemble based on bagging and
decision tree. For bagging, we draw $m$ samples {\em with replacement}
from the training set. According to
$$\lim_{m \to \infty}(1-\frac{1}{m})^m \to \frac{1}{e} \simeq 0.368$$
there are about $63.2 $ percent items may not appear that set. In
random forest, we use this sampling method $N$ times, to construct $N$
training sets and grow $N$ decision trees. Note that we build unpruned
decision trees.

In each node, instead of using the best feature by ID3 , we choose $k$
features randomly and than use the ID3 heuristic to find the best
feature to split on. Generally, $k = log_2 d $ is a good choice where d
is the number of features for our data.

Since there are $N$ trees, there will be $N$ predictions for each
example. Generally, the final prediction is voted on by these trees.
However, we would like to use SVM to combine these predictions for
this question. Specifically, after growing the $N$ decision trees, you
should construct a new $D$ consisting of transformed features. The
feature transformation $\phi(x)$ is defined using the $N$ trees as
follows:

$$\phi(x) = [tree_1(x), tree_2(x), \cdots, tree_{N} (x)]$$  

In other words, you will build an $N$ dimensional vector consisting of
the prediction (1 or -1) of each tree that you created. Thus, you have
a {\em learned} feature transformation.

You will finally train an SVM on this new dataset $D$.

\begin{enumerate}
\item ~[15 points] Using the method mentioned above, construct
  $N = 5$ decision trees for the {\tt handwriting} dataset. For each
  node, select $k = log_2 d = 8$ features randomly and then use the
  ID3 heuristic to find the best feature for splitting.

  Train the SVM meta-classifier and report the accuracy for both
  training set and test set. (No cross-validation is required but
  please choose good parameters for SVM, we will take out points for
  very low accuracy.)
  
  Extensive cross validation was used. The parameters were the same as those used for SVM classification (without the forest) on the madelon dataset.
      \begin{table}[H]
    \centering
    \begin{tabular}{| c | c | c | c | c |}
      \hline
      Data set & Accuracy & Precision & Recall & $F_1$ Score  \\
      \hline
      Test& $0.6897$ & $0.7460$& $0.6046$& $0.6679$\\
      \hline
      Training& $0.7800$ & $0.8475$& $0.7299$& $0.7843$\\
      \hline
   \end{tabular}
    \caption{Accuracy, Precision, Recall and $F_1$ score for classifier run on Handwriting data set with forest of 5 trees}
  \end{table}   


\item ~[25 points] Implement same method on the {\tt madelon}
  dataset. ($k = log_2 d = 11$)
  \begin{enumerate}
  \item ~[20 points] Try $N = 10, 30, 100$. For each $N$, report
    accuracy on training set and test set. ( cross-validation is not
   required, but please choose good parameters for the SVM. )

  Extensive cross validation was used. The parameters were the same as those used for SVM classification (without the forest) on the madelon dataset.
  
      \begin{table}[H]
    \centering
    \begin{tabular}{| c | c | c |}
      \hline
      Data set & Number of Trees & Accuracy \\
      \hline
      Test& $10$ & $0.5533$\\
      \hline
      Test& $30$ & $0.5650$\\
      \hline
      Test& $100$ & $0.5467$\\
      \hline
      Training& $10$ & $0.6285$\\
      \hline
      Training& $30$ & $0.7450$\\
      \hline
      Training& $100$ & $0.8350$\\
      \hline
   \end{tabular}
    \caption{Accuracy by number of trees for classifier run on Madelon data set}
  \end{table}   


  \item ~[5 points] Choose the best $N$ among those you have tried
    (you may try some new numbers). Report the accuracy, precision,
    recall and $f_1$ score on test set.
    
    The $F_1$ score was best with $10$ trees and the accuracy was best with $30$ trees.
          \begin{table}[H]
    \centering
    \begin{tabular}{| c | c | c | c | c |}
      \hline
      Best number of trees & Accuracy &Precision & Recall & $F_1$ Score  \\
      \hline
      $10$ & $0.5533$ & $0.5408$& $0.7067$& $0.6127$\\
      \hline
      $30$ & $0.5650$ & $0.5644$& $0.5700$& $0.5672$\\
      \hline
    \end{tabular}
    \caption{Accuracy, Precision, Recall and $F_1$ score for classifier run on Madelon test data set}
  \end{table}   
    
  \end{enumerate}
\end{enumerate}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "hw"
%%% End:
